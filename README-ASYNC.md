# Асинхронный бенчмарк для JavaScript-рантаймов

## Описание

Этот бенчмарк оценивает эффективность асинхронных операций в различных JavaScript-рантаймах (Node.js, Deno и Bun). Бенчмарк фокусируется на измерении производительности при параллельном выполнении различных типов асинхронных задач, что отражает реальные сценарии использования на серверной стороне.

## Тестируемые операции

Бенчмарк включает следующие типы асинхронных операций:

1. **Файловые операции (I/O)**: Асинхронная запись и чтение данных в/из файла
2. **Эмуляция сетевых запросов**: Имитация задержки сетевых вызовов к внешним сервисам
3. **Таймеры и обработка отложенных операций**: Эмуляция отложенных вычислений

## Методология

Каждый рантайм выполняет набор из нескольких параллельных асинхронных задач при получении HTTP-запроса. Для оценки производительности измеряются следующие параметры:

1. **Время выполнения задач на сервере**: Время, необходимое для параллельного выполнения всех асинхронных операций
2. **Максимальное количество обрабатываемых запросов в секунду (RPS)**: Измеряется с помощью инструмента wrk
3. **Задержка (Latency)**: Время ответа на запросы при различных уровнях нагрузки

## Конфигурация

Бенчмарк можно конфигурировать через переменные окружения:

- `PARALLEL_TASKS`: Количество параллельных асинхронных задач (по умолчанию 10)
- `FILE_OPERATION_SIZE`: Размер файла для операций чтения/записи в байтах (по умолчанию 262144, ~256KB)
- `DELAY_MS`: Эмулируемая задержка для сетевых операций в миллисекундах (по умолчанию 50)

## Запуск бенчмарка

Для запуска всех бенчмарков:

```
./run_all_benchmarks.sh [количество_итераций]
```

Для запуска только асинхронного бенчмарка для конкретного рантайма:

```
./benchmark_async.sh <runtime> [количество_итераций]
```

Где `<runtime>` может быть `node`, `deno` или `bun`, а `[количество_итераций]` - опциональный параметр, определяющий сколько раз следует повторить тест (по умолчанию 1).

## Результаты

Результаты бенчмарка сохраняются в директории `./results/` в формате JSON. Каждый файл результатов содержит данные о конфигурации, всех итерациях теста и агрегированную статистику.

## Интерпретация результатов

При анализе результатов рекомендуется обращать внимание на следующие метрики:

1. `server_async_duration_ms` - время параллельного выполнения асинхронных задач на сервере
2. `requests_per_sec` - количество запросов, которое может обработать сервер в секунду
3. `latency` - задержка при обработке запросов

Более низкое значение `server_async_duration_ms` и более высокое значение `requests_per_sec` указывают на лучшую производительность рантайма в асинхронных операциях.

## Примечания

- Тесты выполняются в Docker-контейнерах для изоляции и воспроизводимости результатов
- Для генерации нагрузки используется инструмент wrk
- Результаты могут различаться в зависимости от аппаратных ресурсов хост-системы 